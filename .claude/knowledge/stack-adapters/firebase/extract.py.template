#!/usr/bin/env python3
"""
Firebase/Firestore Data Extraction Script
=========================================

Generated by: {{kit_name}}
Purpose: {{extraction_purpose}}
Date: {{generated_at}}

This script extracts AGGREGATED metrics from your Firestore database.
Personal information (emails, names) is excluded unless explicitly requested.

Requirements:
- pip install firebase-admin
- Service account JSON file (or GOOGLE_APPLICATION_CREDENTIALS env var)

Usage:
  python3 {{script_name}} [--output metrics.json]
"""

import json
import os
import sys
from datetime import datetime, timedelta
from collections import defaultdict

# Check for firebase-admin
try:
    import firebase_admin
    from firebase_admin import credentials, firestore
except ImportError:
    print("Error: firebase-admin not installed")
    print("Run: pip install firebase-admin")
    sys.exit(1)


# ============================================================================
# CONFIGURATION - Customize for your project
# ============================================================================

# Service account path (or use GOOGLE_APPLICATION_CREDENTIALS env var)
SERVICE_ACCOUNT_PATH = os.getenv(
    'FIREBASE_SERVICE_ACCOUNT',
    os.getenv('GOOGLE_APPLICATION_CREDENTIALS', 'serviceAccountKey.json')
)

# Collection names (from schema discovery)
USERS_COLLECTION = "{{users_collection}}"  # e.g., "users"
CONTENT_COLLECTION = "{{content_collection}}"  # e.g., "content", "posts"
EVENTS_COLLECTION = "{{events_collection}}"  # e.g., "events", "sessions"

# Field mappings (from schema discovery)
USER_FIELDS = {
    "id": "{{user_id_field}}",           # e.g., "uid"
    "created_at": "{{user_created_at}}", # e.g., "createdAt"
    "last_active": "{{user_last_active}}",  # e.g., "lastActive"
    "plan": "{{user_plan_field}}",       # e.g., "plan", "tier", None
}

CONTENT_FIELDS = {
    "user_id": "{{content_user_id}}",    # e.g., "userId"
    "created_at": "{{content_created_at}}",  # e.g., "createdAt"
}

# Sensitive fields to EXCLUDE from any output
SENSITIVE_FIELDS = ["email", "displayName", "name", "phone", "photoURL"]


# ============================================================================
# HELPER FUNCTIONS
# ============================================================================

def init_firebase():
    """Initialize Firebase Admin SDK."""
    if not os.path.exists(SERVICE_ACCOUNT_PATH):
        print(f"Error: Service account file not found: {SERVICE_ACCOUNT_PATH}")
        print("\nTo fix this:")
        print("1. Go to Firebase Console > Project Settings > Service Accounts")
        print("2. Generate new private key")
        print("3. Save as 'serviceAccountKey.json' in this directory")
        print("   OR set GOOGLE_APPLICATION_CREDENTIALS env var")
        sys.exit(1)

    cred = credentials.Certificate(SERVICE_ACCOUNT_PATH)
    firebase_admin.initialize_app(cred)
    return firestore.client()


def to_datetime(timestamp):
    """Convert Firestore Timestamp to Python datetime."""
    if timestamp is None:
        return None
    if hasattr(timestamp, 'seconds'):
        return datetime.fromtimestamp(timestamp.seconds)
    if isinstance(timestamp, datetime):
        return timestamp
    return None


def anonymize_id(doc_id: str) -> str:
    """Create anonymized ID for output."""
    return f"user_{hash(doc_id) % 100000:05d}"


def get_field(doc_dict: dict, field_name: str, default=None):
    """Safely get field from document, handling nested paths."""
    if not field_name or field_name == "None":
        return default

    parts = field_name.split('.')
    value = doc_dict
    for part in parts:
        if isinstance(value, dict) and part in value:
            value = value[part]
        else:
            return default
    return value


# ============================================================================
# DATA EXTRACTION
# ============================================================================

def extract_users(db) -> list:
    """Extract user data (anonymized)."""
    users = []

    docs = db.collection(USERS_COLLECTION).stream()
    for doc in docs:
        data = doc.to_dict()

        user = {
            "anon_id": anonymize_id(doc.id),
            "created_at": to_datetime(get_field(data, USER_FIELDS["created_at"])),
            "last_active": to_datetime(get_field(data, USER_FIELDS["last_active"])),
        }

        # Add plan if tracked
        if USER_FIELDS.get("plan"):
            user["plan"] = get_field(data, USER_FIELDS["plan"], "unknown")

        # Skip if no created_at (invalid record)
        if user["created_at"]:
            users.append(user)

    return users


def extract_content_counts(db) -> dict:
    """Extract content counts per user (no content data)."""
    if not CONTENT_COLLECTION or CONTENT_COLLECTION == "None":
        return {}

    counts = defaultdict(int)

    docs = db.collection(CONTENT_COLLECTION).stream()
    for doc in docs:
        data = doc.to_dict()
        user_id = get_field(data, CONTENT_FIELDS["user_id"])
        if user_id:
            counts[anonymize_id(user_id)] += 1

    return dict(counts)


def extract_events_summary(db) -> dict:
    """Extract event summary per user (no raw events)."""
    if not EVENTS_COLLECTION or EVENTS_COLLECTION == "None":
        return {}

    summary = defaultdict(lambda: {"count": 0, "first": None, "last": None})

    docs = db.collection(EVENTS_COLLECTION).stream()
    for doc in docs:
        data = doc.to_dict()
        user_id = get_field(data, "userId")  # Common pattern
        if not user_id:
            continue

        anon_id = anonymize_id(user_id)
        timestamp = to_datetime(get_field(data, "timestamp") or get_field(data, "createdAt"))

        summary[anon_id]["count"] += 1
        if timestamp:
            if not summary[anon_id]["first"] or timestamp < summary[anon_id]["first"]:
                summary[anon_id]["first"] = timestamp
            if not summary[anon_id]["last"] or timestamp > summary[anon_id]["last"]:
                summary[anon_id]["last"] = timestamp

    return {k: dict(v) for k, v in summary.items()}


# ============================================================================
# METRICS CALCULATION
# ============================================================================

def calculate_metrics(users: list, content_counts: dict, events_summary: dict) -> dict:
    """Calculate aggregated metrics."""
    now = datetime.now()
    day_7_ago = now - timedelta(days=7)
    day_30_ago = now - timedelta(days=30)

    total = len(users)
    if total == 0:
        return {"error": "No users found"}

    # Activity metrics
    active_7d = sum(1 for u in users if u["last_active"] and u["last_active"] > day_7_ago)
    active_30d = sum(1 for u in users if u["last_active"] and u["last_active"] > day_30_ago)

    # Content metrics (activation proxy)
    users_with_content = sum(1 for u in users if content_counts.get(u["anon_id"], 0) > 0)

    # Signup cohorts (last 4 weeks)
    cohorts = []
    for weeks_ago in range(4):
        start = now - timedelta(weeks=weeks_ago + 1)
        end = now - timedelta(weeks=weeks_ago)
        cohort_users = [u for u in users if u["created_at"] and start <= u["created_at"] < end]
        cohort_retained = sum(1 for u in cohort_users if u["last_active"] and u["last_active"] > day_7_ago)
        cohorts.append({
            "week": f"W-{weeks_ago + 1}",
            "start": start.isoformat(),
            "signups": len(cohort_users),
            "retained_7d": cohort_retained,
            "retention_rate": round(cohort_retained / len(cohort_users), 2) if cohort_users else 0
        })

    # Plan distribution
    plans = defaultdict(int)
    for u in users:
        plans[u.get("plan", "unknown")] += 1

    return {
        "extracted_at": now.isoformat(),
        "totals": {
            "users": total,
            "active_7d": active_7d,
            "active_30d": active_30d,
            "with_content": users_with_content
        },
        "rates": {
            "active_7d_rate": round(active_7d / total, 3),
            "active_30d_rate": round(active_30d / total, 3),
            "activation_rate": round(users_with_content / total, 3)
        },
        "cohorts": cohorts,
        "plans": dict(plans),
        "content": {
            "total_items": sum(content_counts.values()),
            "avg_per_user": round(sum(content_counts.values()) / total, 2) if total else 0,
            "users_with_content": users_with_content
        }
    }


# ============================================================================
# MAIN
# ============================================================================

def main():
    import argparse
    parser = argparse.ArgumentParser(description='Extract metrics from Firestore')
    parser.add_argument('--output', '-o', default='metrics.json', help='Output file')
    args = parser.parse_args()

    print("Initializing Firebase...")
    db = init_firebase()

    print(f"Extracting users from '{USERS_COLLECTION}'...")
    users = extract_users(db)
    print(f"  Found {len(users)} users")

    print(f"Extracting content counts from '{CONTENT_COLLECTION}'...")
    content_counts = extract_content_counts(db)
    print(f"  Found {sum(content_counts.values())} content items")

    print(f"Extracting events summary from '{EVENTS_COLLECTION}'...")
    events_summary = extract_events_summary(db)
    print(f"  Found events for {len(events_summary)} users")

    print("Calculating metrics...")
    metrics = calculate_metrics(users, content_counts, events_summary)

    # Save output
    with open(args.output, 'w') as f:
        json.dump(metrics, f, indent=2, default=str)

    print(f"\nâœ“ Metrics saved to {args.output}")
    print("\nSummary:")
    print(f"  Total users: {metrics['totals']['users']}")
    print(f"  Active (7d): {metrics['totals']['active_7d']} ({metrics['rates']['active_7d_rate']:.1%})")
    print(f"  Activated: {metrics['totals']['with_content']} ({metrics['rates']['activation_rate']:.1%})")

    print(f"\nShare {args.output} with the kit for analysis.")


if __name__ == "__main__":
    main()
